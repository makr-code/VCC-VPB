# AI Chat Terminal - Wiederherstellung & Integration

## Ãœbersicht

Der **AI Chat Terminal** wurde wiederhergestellt und in die refaktorisierte VPB Application integriert. Der Chat ermÃ¶glicht natÃ¼rlichsprachliche Interaktion mit dem Canvas Ã¼ber ein Ollama-Backend.

## Status

âœ… **Wiederhergestellt:** AI Chat Terminal ist funktional
âœ… **Integriert:** In vertikalem PanedWindow unter dem Content-Bereich
âœ… **Controller:** ChatController mit allen Legacy-Methoden
âœ… **UI:** ChatPanel mit Eingabe, Historie und Task-Manager

## Architektur

### Komponenten

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VPB Application (vpb_app.py)               â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         Content Area (Diagram/Code/XML)           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚ â”‚
â”‚  â”‚  â”‚ Palette â”‚    Canvas    â”‚  Properties â”‚        â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†• Resizable Sash                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           AI Chat Terminal (height=200)           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  ChatPanel                                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Message History                           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Input Field                               â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Send/Stop Buttons                         â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  ChatController                                   â”‚ â”‚
â”‚  â”‚  - handle_send()                                  â”‚ â”‚
â”‚  â”‚  - handle_stop()                                  â”‚ â”‚
â”‚  â”‚  - handle_attach()                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dateien

**Existierende Komponenten:**
- `vpb/ui/chat_panel.py` - Chat UI (Eingabe, Historie)
- `vpb/ui/chat_controller.py` - Chat-Logik & Ollama-Integration
- `vpb/ui/chat_console.py` - Hilfsfunktion zum Erstellen des Chats
- `vpb/ui/task_manager.py` - Background-Task-Manager

**Integration in vpb_app.py:**
- `_init_chat_terminal()` - Initialisiert Chat-Komponenten
- Chat-Methoden fÃ¼r Canvas-Manipulation
- Ollama-Konfiguration

## Integration in vpb_app.py

### Initialisierung

```python
class VPBApplication:
    def __init__(self, args=None):
        # Ollama Settings
        self._ollama_endpoint = "http://localhost:11434"
        self._ollama_model = "llama3.2"
        self._ollama_temperature = 0.7
        self._ollama_num_predict = 2048
        
    def _init_views(self):
        # Vertical Split: Content + Chat
        self.vertical_paned = tk.PanedWindow(orient=tk.VERTICAL)
        
        # Content Area (Diagram/Code/XML)
        content_area = tk.Frame(self.vertical_paned)
        self.vertical_paned.add(content_area, minsize=400)
        
        # AI Chat Terminal
        self._init_chat_terminal(self.vertical_paned)
```

### Chat Terminal Setup

```python
def _init_chat_terminal(self, parent):
    """Initialisiert den AI Chat Terminal."""
    from vpb.ui.chat_console import create_chat_console
    from vpb.ui.chat_controller import ChatController
    
    # Chat Terminal Container
    chat_frame = tk.Frame(parent)
    parent.add(chat_frame, minsize=150, height=200)
    
    # Chat Controller erstellen
    self.chat_controller = ChatController(self)  # â† self statt self.root!
    
    # Chat Console erstellen
    self.chat_container, self.chat_panel, self.task_manager = create_chat_console(
        self.root,
        chat_frame,
        on_send=self.chat_controller.handle_send,
        on_stop=self.chat_controller.handle_stop,
        on_attach=self.chat_controller.handle_attach,
    )
    
    # Controller mit UI verbinden
    self.chat_controller.bind_ui(self.chat_panel, self.task_manager)
```

### Canvas-Manipulations-Methoden

```python
def _apply_full_process_json(self, parsed_data):
    """Wendet vollstÃ¤ndigen Prozess-JSON an (Replace)."""
    self.canvas.load_from_dict(parsed_data)
    self.canvas.redraw_all()
    self.status.set("âœ… Prozess vollstÃ¤ndig ersetzt")

def _merge_full_process_json(self, parsed_data):
    """Merged Prozess-JSON mit existierendem Canvas."""
    # Neue Elemente/Connections hinzufÃ¼gen
    for elem in parsed_data.get('elements', []):
        if elem_id not in self.canvas.elements:
            new_elem = VPBElement.from_dict(elem)
            self.canvas.elements[elem_id] = new_elem
    self.canvas.redraw_all()

def _apply_add_only_patch(self, parsed_data):
    """Wendet Add-Only Patch an (nur neue Elemente)."""
    # Nur Elemente mit neuen IDs hinzufÃ¼gen
    # ...

def _apply_diagnose_patch(self, parsed_data):
    """Wendet Diagnose-Patch an (Fehlerbehebungen)."""
    # Korrigiert existierende Elemente basierend auf Diagnose
    # ...

def _ensure_chat_visible(self):
    """Stellt sicher, dass Chat sichtbar ist."""
    pass  # TODO: Implementierung wenn minimierbar
```

## ChatController Anforderungen

Der `ChatController` erwartet von der App folgende Attribute/Methoden:

### Erforderliche Attribute

```python
# Ollama Configuration
self._ollama_endpoint    # "http://localhost:11434"
self._ollama_model       # "llama3.2"
self._ollama_temperature # 0.7
self._ollama_num_predict # 2048

# Canvas Reference
self.canvas              # VPBCanvas Instanz

# Status Feedback
self.status              # Property mit .set(message) Methode
```

### Erforderliche Methoden

```python
# Canvas-Manipulation
self._apply_full_process_json(parsed_data)  # Replace
self._merge_full_process_json(parsed_data)  # Merge
self._apply_add_only_patch(parsed_data)     # Add Only
self._apply_diagnose_patch(parsed_data)     # Diagnose & Fix

# UI Control
self._ensure_chat_visible()                 # Chat einblenden
```

## Ollama-Konfiguration

### Default Settings

```python
{
    "endpoint": "http://localhost:11434",
    "model": "llama3.2",
    "temperature": 0.7,
    "num_predict": 2048
}
```

### Anpassung (TODO)

```python
# In settings.json
{
    "ollama": {
        "endpoint": "http://localhost:11434",
        "model": "llama3.2:latest",
        "temperature": 0.5,
        "num_predict": 4096
    }
}

# In vpb_app.py
settings = self.settings_manager.get("ollama", {})
self._ollama_endpoint = settings.get("endpoint", "http://localhost:11434")
self._ollama_model = settings.get("model", "llama3.2")
```

## Chat-Funktionen

### 1. Prozess-Generierung

**User:** "Erstelle einen Prozess fÃ¼r Baugenehmigung mit Start, 3 Aufgaben und Ende"

**Chat Response:**
```json
{
  "elements": [
    {"id": "E1", "type": "START_EVENT", "name": "Antrag einreichen", ...},
    {"id": "E2", "type": "TASK", "name": "Unterlagen prÃ¼fen", ...},
    {"id": "E3", "type": "TASK", "name": "Genehmigung prÃ¼fen", ...},
    {"id": "E4", "type": "TASK", "name": "Bescheid erstellen", ...},
    {"id": "E5", "type": "END_EVENT", "name": "Genehmigung erteilt", ...}
  ],
  "connections": [...]
}
```

**Action:** Apply-Button â†’ `_apply_full_process_json()` â†’ Canvas zeigt Prozess

### 2. Prozess-Erweiterung

**User:** "FÃ¼ge eine Entscheidung 'Ist vollstÃ¤ndig?' nach der PrÃ¼fung hinzu"

**Chat Response:**
```json
{
  "elements": [
    {"id": "E6", "type": "GATEWAY", "name": "Ist vollstÃ¤ndig?", ...}
  ],
  "connections": [
    {"id": "C5", "source": "E2", "target": "E6", ...},
    {"id": "C6", "source": "E6", "target": "E3", "label": "Ja", ...},
    {"id": "C7", "source": "E6", "target": "E1", "label": "Nein", ...}
  ]
}
```

**Action:** Merge-Button â†’ `_merge_full_process_json()` â†’ Neue Elemente hinzugefÃ¼gt

### 3. Prozess-Diagnose

**User:** "PrÃ¼fe den Prozess auf Fehler"

**Chat Response:**
```json
{
  "issues": [
    {"type": "warning", "element": "E3", "message": "Keine Rechtsgrundlage angegeben"},
    {"type": "error", "element": "E4", "message": "Keine ausgehende Verbindung"}
  ],
  "fixes": [
    {"element_id": "E3", "legal_basis": "BauGB Â§29"},
    {"element_id": "E4", "connections": [...]}
  ]
}
```

**Action:** Fix-Button â†’ `_apply_diagnose_patch()` â†’ Korrekturen angewendet

## UI Layout

### Vertical PanedWindow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Content Area                            â”‚
â”‚  (Canvas, Code, XML Tabs)                               â”‚
â”‚                  minsize=400                            â”‚
â”‚                                                         â”‚
â”‚                                                         â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â† Resizable Sash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            AI Chat Terminal                             â”‚
â”‚  minsize=150, height=200                                â”‚
â”‚                                                         â”‚
â”‚  > User: Erstelle einen Prozess...                     â”‚
â”‚  ğŸ¤– Assistant: Hier ist der Prozess:                   â”‚
â”‚  [Apply] [Merge] [Fix]                                 â”‚
â”‚                                                         â”‚
â”‚  [_________________________________] [Send] [Stop]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Chat Panel Features

**Message History:**
- User-Messages (rechts, blau)
- Assistant-Messages (links, grau)
- System-Messages (zentriert, gelb)
- Code-Blocks (monospace, dunkler Hintergrund)

**Action Buttons:**
- ğŸ”„ **Apply** - Wendet JSON vollstÃ¤ndig an (Replace)
- â• **Merge** - FÃ¼gt neue Elemente hinzu
- ğŸ”§ **Fix** - Wendet Diagnose-Korrekturen an
- ğŸ“‹ **Copy** - Kopiert JSON in Zwischenablage

**Input Field:**
- Multiline Text-Eingabe
- Auto-Resize bei langem Text
- Strg+Enter zum Senden

**Control Buttons:**
- ğŸ“¤ **Send** - Sendet Message an Ollama
- â›” **Stop** - Bricht laufende Anfrage ab
- ğŸ“ **Attach** - FÃ¼gt Canvas-Kontext hinzu

## Status Feedback

### Status Property

```python
@property
def status(self):
    """Legacy-KompatibilitÃ¤t fÃ¼r status.set()"""
    class StatusProxy:
        def __init__(self, status_bar):
            self._status_bar = status_bar
        
        def set(self, message):
            if self._status_bar:
                self._status_bar.set_message(message)
    
    return StatusProxy(self.status_bar)
```

### Chat Status Messages

```python
# Chat lÃ¤uft
self.status.set("AI: Chat gestartet")

# Chat fertig
self.status.set("AI: Chat fertig")

# Fehler
self.status.set("AI: Kein laufender Chat")

# Prozess-Manipulation
self.status.set("âœ… Prozess vollstÃ¤ndig ersetzt")
self.status.set("âœ… Prozess gemerged")
self.status.set("âœ… 5 neue Elemente hinzugefÃ¼gt")
self.status.set("âœ… 3 Korrekturen angewendet")
```

## Bekannte Limitations

### 1. Ollama muss laufen

**Problem:** Chat funktioniert nur wenn Ollama-Server lÃ¤uft

**LÃ¶sung:**
```bash
# Ollama starten
ollama serve

# Model herunterladen
ollama pull llama3.2
```

**Error Handling:**
```python
try:
    response = ollama.chat(...)
except Exception as e:
    self.status.set(f"âŒ Ollama Fehler: {e}")
```

### 2. Keine Chat-History Persistierung

**Problem:** Chat-Historie geht beim SchlieÃŸen verloren

**LÃ¶sung (TODO):**
```python
# In settings_manager
def save_chat_history(self, messages):
    with open("chats/chat_history.json", "w") as f:
        json.dump(messages, f)

def load_chat_history(self):
    with open("chats/chat_history.json", "r") as f:
        return json.load(f)
```

### 3. Chat nicht minimierbar/versteckbar

**Problem:** Chat nimmt immer Platz ein (minsize=150)

**LÃ¶sung (TODO):**
```python
def toggle_chat_terminal(self):
    if self.chat_visible:
        self.vertical_paned.remove(self.chat_frame)
        self.chat_visible = False
    else:
        self.vertical_paned.add(self.chat_frame, minsize=150, height=200)
        self.chat_visible = True
```

## Testing

### Manuelle Tests

**Test 1: Chat Terminal anzeigen**
```
1. âœ… App starten
2. âœ… Chat Terminal ist sichtbar unten
3. âœ… Input-Feld funktioniert
4. âœ… Send-Button vorhanden
```

**Test 2: Ollama-Integration (wenn Ollama lÃ¤uft)**
```
1. â³ Nachricht eingeben "Hallo"
2. â³ Send klicken
3. â³ Assistant antwortet
4. â³ Message in Historie sichtbar
```

**Test 3: Canvas-Manipulation**
```
1. â³ "Erstelle einen einfachen Prozess" eingeben
2. â³ Apply-Button klicken
3. â³ Canvas zeigt generierten Prozess
4. â³ Status: "âœ… Prozess vollstÃ¤ndig ersetzt"
```

**Test 4: Status-Feedback**
```
1. âœ… Chat-Nachricht senden
2. âœ… Status: "AI: Chat gestartet"
3. âœ… Nach Antwort: "AI: Chat fertig"
```

## ZukÃ¼nftige Erweiterungen

### Phase 1: Chat-UX
- â³ Chat minimieren/maximieren
- â³ Chat-Historie speichern (JSON)
- â³ Keyboard Shortcuts (Strg+Enter, Esc)
- â³ Auto-Scroll bei neuen Messages

### Phase 2: Erweiterte Features
- â³ Canvas-Screenshot als Kontext mitschicken
- â³ Multi-Turn Conversations
- â³ Conversation Branching
- â³ Export Chat als Markdown

### Phase 3: AI-Funktionen
- â³ Process-Validation via AI
- â³ Process-Optimization Suggestions
- â³ Automated Testing via AI
- â³ Natural Language Queries ("Zeige mir alle Gateways")

## Zusammenfassung

**Vorher:**
- âŒ Chat Terminal war in Legacy-Code eingebunden
- âŒ Nicht kompatibel mit refaktorisierter Architektur
- âŒ Fehlende Methoden und Attribute

**Nachher:**
- âœ… Chat Terminal wiederhergestellt
- âœ… Integration in vertikalem PanedWindow
- âœ… ChatController funktionsfÃ¤hig
- âœ… Alle erforderlichen Methoden implementiert
- âœ… Status-Feedback funktioniert
- âœ… Canvas-Manipulation (Replace, Merge, Add, Fix)
- âœ… Ollama-Konfiguration vorhanden

**Status:** âœ… Wiederhergestellt und funktional (abhÃ¤ngig von Ollama-Server)

**NÃ¤chste Schritte:**
1. Ollama-Server testen
2. Chat-Historie implementieren
3. Chat minimierbar machen
4. Erweiterte AI-Funktionen hinzufÃ¼gen
